2025-07-10 14:01:53,288 - INFO - Sample train set 1500/67349
2025-07-10 14:01:53,288 - INFO - ... including dev set 500 samples
2025-07-10 14:01:53,289 - INFO - Loading model with FP16...
/home/rinya/anaconda3/envs/zollm/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
39
2025-07-10 14:01:57,203 - INFO - Done with 3.91s
2025-07-10 14:01:57,508 - INFO - Dev samples: 500
2025-07-10 14:01:57,508 - INFO - Train samples: 1000
2025-07-10 14:01:57,509 - INFO - Eval sample length is 872
2025-07-10 14:01:57,509 - INFO - Tokenizing training samples...
2025-07-10 14:01:58,396 - INFO - Done with 0.89s
/home/rinya/anaconda3/envs/zollm/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Traceback (most recent call last):
  File "/home/rinya/zero-order-optimization/src/run.py", line 740, in <module>
    main()
  File "/home/rinya/zero-order-optimization/src/run.py", line 692, in main
    framework.train(train_samples, dev_samples if dev_samples is not None else eval_samples, eval_samples)
  File "/home/rinya/zero-order-optimization/src/run.py", line 577, in train
    trainer.train(resume_from_checkpoint=last_checkpoint)
  File "/home/rinya/anaconda3/envs/zollm/lib/python3.10/site-packages/transformers/trainer.py", line 1662, in train
    return inner_training_loop(
  File "/home/rinya/zero-order-optimization/src/trainer.py", line 351, in _inner_training_loop
    self.optimizer = ZO_MUON(self, self.model.parameters(), args) # TODO: add for other optimizers
  File "/home/rinya/zero-order-optimization/src/optimizers/zo_muon.py", line 8, in __init__
    super().__init__(trainer, params, args)
  File "/home/rinya/zero-order-optimization/src/optimizers/base.py", line 11, in __init__
    super().__init__(params, defaults)
  File "/home/rinya/anaconda3/envs/zollm/lib/python3.10/site-packages/torch/optim/optimizer.py", line 261, in __init__
    raise ValueError("optimizer got an empty parameter list")
ValueError: optimizer got an empty parameter list
OPTForCausalLM(
  (model): OPTModel(
    (decoder): OPTDecoder(
      (embed_tokens): Embedding(50272, 2048, padding_idx=1)
      (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)
      (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
      (layers): ModuleList(
        (0-23): 24 x OPTDecoderLayer(
          (self_attn): OPTAttention(
            (k_proj): Linear(in_features=2048, out_features=2048, bias=True)
            (v_proj): Linear(in_features=2048, out_features=2048, bias=True)
            (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)
          )
          (activation_fn): ReLU()
          (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=2048, out_features=8192, bias=True)
          (fc2): Linear(in_features=8192, out_features=2048, bias=True)
          (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (lm_head): Linear(in_features=2048, out_features=50272, bias=False)
)
PARAMS []